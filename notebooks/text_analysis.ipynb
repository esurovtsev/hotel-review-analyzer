{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Text Analysis with OpenAI API\n",
    "This notebook demonstrates how to use the OpenAI API for text analysis. We will:\n",
    "1. Test the OpenAI API connection.\n",
    "2. Analyze a single text for sentiment and key topics.\n",
    "3. Process multiple texts and save the results to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "openai_model = \"gpt-4o-mini\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=openai_model\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Analyze a Single Text\n",
    "We will send a single piece of text to the OpenAI API and request:\n",
    "1. Sentiment analysis (positive, neutral, negative).\n",
    "2. Extraction of key topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "openai_temperature=0.7\n",
    "\n",
    "def analyze_text_with_openai(text):\n",
    "    \"\"\"\n",
    "    Analyze a single text using OpenAI API for sentiment and key topics, returning structured JSON output.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict: Structured analysis results including key topics and sentiment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant for text analysis.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": f\"\"\"\n",
    "                        Analyze the following text and provide the result in JSON format. The JSON should include:\n",
    "                        - \"key_topics\": A list of key topics mentioned in the text.\n",
    "                        - \"sentiment\": An object that contains a summary of the overall sentiment (only values allowed as overal sentiment are: \"positive\", \"neutral\", or \"negative\") along with reasoning.\n",
    "\n",
    "                        Text: {text}\n",
    "\n",
    "                        Your response should be in JSON format. Do not include any explanations, only provide a RFC8259 compliant.\n",
    "\n",
    "                        The JSON output should be in the following format:\n",
    "                        {{\n",
    "                            \"key_topics\": [\n",
    "                                \"hotel cleanliness\",\n",
    "                                \"service speed\"\n",
    "                            ],\n",
    "                            \"sentiment\": {{\n",
    "                                \"summary\": \"neutral\",\n",
    "                                \"reasoning\": \"the text mentions a positive aspect of cleanliness\"\n",
    "                            }}\n",
    "                        }}\n",
    "\n",
    "                        Do not include markdown code blocks in your response. Remove the ```json markdown from the output.\n",
    "                    \"\"\"\n",
    "                }\n",
    "            ],\n",
    "            model=openai_model,\n",
    "            temperature=openai_temperature\n",
    "        )\n",
    "\n",
    "        # Parse the JSON output from the response\n",
    "        structured_analysis = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Validate and parse the JSON output\n",
    "        if not structured_analysis:\n",
    "            print(\"Error: Received an empty response from OpenAI.\")\n",
    "            return None\n",
    "\n",
    "        # Convert the JSON string to a Python dictionary\n",
    "        analysis_result = json.loads(structured_analysis)\n",
    "        analysis_result[\"review\"] = text\n",
    "        return analysis_result\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        print(\"Raw Response:\", structured_analysis)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing text: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the updated function with a sample text\n",
    "sample_text = \"The hotel was clean, but the service was slow and unhelpful.\"\n",
    "# Call the function\n",
    "result = analyze_text_with_openai(sample_text)\n",
    "# Display the result\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Batch Process Multiple Texts\n",
    "We will apply the text analysis function to multiple texts from a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset of texts\n",
    "data = pd.DataFrame({\n",
    "    \"text\": [\n",
    "        \"The hotel was amazing, and the staff was very helpful.\",\n",
    "        \"The room was dirty, and the food was terrible.\",\n",
    "        \"Good location, but the service was slow.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Apply the function to each text\n",
    "data['analysis'] = data['text'].apply(analyze_text_with_openai)\n",
    "\n",
    "# Display the results\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Save Analysis Results to JSON\n",
    "\n",
    "In this step, we save the analyzed results to a JSON file. The JSON format provides a clear structure for the data, making it easier to read and process in downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a JSON file\n",
    "output_file = \"../data/processed/text_analysis_results.json\"\n",
    "\n",
    "# Convert the DataFrame's 'analysis' column to a list of dictionaries\n",
    "results = data['analysis'].tolist()\n",
    "\n",
    "# Save the list to a JSON file\n",
    "with open(output_file, \"w\") as json_file:\n",
    "    json.dump(results, json_file, indent=4)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Group Reviews by Sentiment\n",
    "\n",
    "In this step, we group the reviews into three categories:\n",
    "1. Positive\n",
    "2. Negative\n",
    "3. Neutral\n",
    "\n",
    "The reviews are grouped based on the `sentiment[\"summary\"]` field from the analysis JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the analysis results\n",
    "input_file = \"../data/processed/text_analysis_results.json\"\n",
    "with open(input_file, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Group reviews by sentiment\n",
    "grouped_reviews = {\"positive\": [], \"negative\": [], \"neutral\": []}\n",
    "\n",
    "for entry in data:\n",
    "    sentiment = entry[\"sentiment\"][\"summary\"]\n",
    "    if sentiment in grouped_reviews:\n",
    "        grouped_reviews[sentiment].append(entry)\n",
    "\n",
    "# Display grouped reviews counts\n",
    "for sentiment, reviews in grouped_reviews.items():\n",
    "    print(f\"{sentiment.capitalize()} reviews: {len(reviews)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Create Common Lists of Key Topics for Each Sentiment (Adjusting Neutral)\n",
    "\n",
    "In this step:\n",
    "1. For each sentiment category (positive and negative), we aggregate `key_topics`.\n",
    "2. Neutral reviews are excluded for now to maintain focus on clear positive and negative insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for key topics (excluding neutral for now)\n",
    "key_topics_by_sentiment = {\"positive\": [], \"negative\": []}\n",
    "\n",
    "# Aggregate key topics by sentiment\n",
    "for sentiment, reviews in grouped_reviews.items():\n",
    "    if sentiment == \"neutral\":\n",
    "        continue  # Skip neutral for now\n",
    "    for review in reviews:\n",
    "        key_topics_by_sentiment[sentiment].extend(review[\"key_topics\"])\n",
    "\n",
    "# Display results\n",
    "for sentiment, topics in key_topics_by_sentiment.items():\n",
    "    print(f\"\\nKey Topics for {sentiment.capitalize()} Sentiment (Excluding Neutral):\")\n",
    "    print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Define and Test `generalize_key_topics_with_openai`\n",
    "\n",
    "### Why This Function is Necessary\n",
    "\n",
    "In our analysis pipeline, we need to generalize raw `key_topics` into broader categories while maintaining traceability to the original topics:\n",
    "1. **Traceability**:\n",
    "   - Grouped categories should map back to their specific topics for detailed analysis.\n",
    "   - This helps us identify which specific issues contributed to each general topic.\n",
    "   \n",
    "2. **Actionable Insights**:\n",
    "   - By generalizing topics, we reduce redundancy and simplify reporting.\n",
    "   - This allows us to calculate meaningful statistics and generate recommendations effectively.\n",
    "\n",
    "### Goals of This Step\n",
    "\n",
    "1. Define the `generalize_key_topics_with_openai` function.\n",
    "2. Test it with a small sample of topics to ensure it works correctly.\n",
    "3. Validate that AI returns generalized topics as a JSON object mapping general categories to specific topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_key_topics_with_openai(topics_list):\n",
    "    \"\"\"\n",
    "    Use OpenAI to group similar topics and generalize them, while maintaining traceability.\n",
    "\n",
    "    Args:\n",
    "        topics_list (list of str): A flat list of all topics for a specific sentiment.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping generalized topics to their specific topics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare topics as input for AI\n",
    "        topics_string = \"\\n\".join(topics_list)\n",
    "        prompt = f\"\"\"\n",
    "            Group the following topics into specific, distinct categories based on logical themes. Avoid overly broad or generic groupings. \n",
    "\n",
    "            Each generalized topic should clearly represent a single theme, such as cleanliness, service, food, or facilities. Do not combine unrelated topics into the same group.\n",
    "\n",
    "            Your goal is to maximize diversity in categories while keeping logical connections. \n",
    "            Provide each generalized topic as a key, and list the specific topics it includes as values.\n",
    "            Do not include any explanations, only provide a JSON outputR that is FC8259 compliant.\n",
    "\n",
    "            Topics:\n",
    "            {topics_string}\n",
    "\n",
    "            Example output:\n",
    "            {{\n",
    "            \"Cleanliness\": [\"room cleanliness\"],\n",
    "            \"Staff Performance\": [\"staff helpfulness\", \"service speed\"],\n",
    "            \"Food Quality\": [\"food quality\", \"breakfast variety\"],\n",
    "            \"Overall Hotel Quality\": [\"hotel quality\"]\n",
    "            }}\n",
    "\n",
    "            Do not include markdown code blocks in your response. Remove the ```json markdown from the output.\n",
    "        \"\"\"\n",
    "        # Send the request to OpenAI\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant for topic analysis.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=openai_model,\n",
    "            temperature=openai_temperature\n",
    "        )\n",
    "\n",
    "        # Parse the JSON response\n",
    "        generalized_topics = json.loads(response.choices[0].message.content.strip())\n",
    "        return generalized_topics\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generalizing topics with OpenAI: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Sample topics to test the function\n",
    "sample_topics = [\n",
    "    \"hotel quality\",\n",
    "    \"room cleanliness\",\n",
    "    \"staff helpfulness\",\n",
    "    \"service speed\",\n",
    "    \"food quality\",\n",
    "    \"breakfast variety\"\n",
    "]\n",
    "\n",
    "# Test the generalization function\n",
    "generalized_topics = generalize_key_topics_with_openai(sample_topics)\n",
    "\n",
    "# Display the results\n",
    "print(\"Sample Topics:\")\n",
    "print(sample_topics)\n",
    "\n",
    "print(\"\\nGeneralized Topics Returned by AI:\")\n",
    "print(json.dumps(generalized_topics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Apply Generalization to Aggregated Topics\n",
    "\n",
    "In this step:\n",
    "1. Use the `generalize_key_topics_with_openai` function to generalize the aggregated `key_topics` for positive and negative sentiments.\n",
    "2. Replace the original `key_topics` in the dataset with their corresponding generalized topics.\n",
    "3. Save the updated dataset to a new JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage for generalized topics\n",
    "generalized_topics_by_sentiment = {}\n",
    "\n",
    "# Apply generalization for positive and negative sentiments\n",
    "for sentiment, topics in key_topics_by_sentiment.items():\n",
    "    print(f\"Generalizing topics for {sentiment.capitalize()} sentiment...\")\n",
    "    generalized_topics = generalize_key_topics_with_openai(topics)\n",
    "    generalized_topics_by_sentiment[sentiment] = generalized_topics\n",
    "    print(f\"Generalized Topics for {sentiment.capitalize()} Sentiment:\")\n",
    "    print(json.dumps(generalized_topics, indent=4))\n",
    "\n",
    "# Extend reviews with generalized topics\n",
    "for sentiment, reviews in grouped_reviews.items():\n",
    "    if sentiment in generalized_topics_by_sentiment:\n",
    "        generalized_topics = generalized_topics_by_sentiment[sentiment]\n",
    "        for review in reviews:\n",
    "            review[\"generalized_key_topics\"] = list({\n",
    "                general_topic\n",
    "                for general_topic, specific_topics in generalized_topics.items()\n",
    "                if any(specific_topic in review[\"key_topics\"] for specific_topic in specific_topics)\n",
    "            })\n",
    "\n",
    "# Save the updated dataset\n",
    "output_file = \"../data/processed/text_analysis_generalized.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(f\"Generalized topics and updated dataset saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
